# Scrape Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãƒ„ãƒ¼ãƒ«

åŠ¹ç‡çš„ã§å®‰å…¨ãªWebã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚’å®Ÿç¾ã™ã‚‹Pythonãƒ„ãƒ¼ãƒ«ã‚»ãƒƒãƒˆã§ã™ã€‚robots.txtã®è¦å‰‡ã‚’éµå®ˆã—ã€é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚„å†å¸°çš„ãªãƒªãƒ³ã‚¯æŠ½å‡ºæ©Ÿèƒ½ã‚’å‚™ãˆã¦ã„ã¾ã™ã€‚

## ä¸»ãªæ©Ÿèƒ½

- ğŸ¤– robots.txtã®è‡ªå‹•è§£æã¨éµå®ˆ
- ğŸ“Š MySQLã¸ã®ãƒ‡ãƒ¼ã‚¿è‡ªå‹•ä¿å­˜
- ğŸ”— ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒªãƒ³ã‚¯æŠ½å‡ºï¼ˆç”»åƒaltå±æ€§ã®è§£æå«ã‚€ï¼‰
- ğŸ”„ ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆSHA-256ãƒãƒƒã‚·ãƒ¥ã«ã‚ˆã‚‹ï¼‰
- ğŸŒ² å†å¸°çš„ãªã‚¯ãƒ­ãƒ¼ãƒªãƒ³ã‚°æ©Ÿèƒ½
- âš ï¸ åŒ…æ‹¬çš„ãªã‚¨ãƒ©ãƒ¼å‡¦ç†ã¨ãƒ­ã‚°è¨˜éŒ²

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

- `config.py`: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
- `models.py`: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œ
- `robots_handler.py`: robots.txtã®å–å¾—ã¨è§£æ
- `link_extractor.py`: ãƒªãƒ³ã‚¯ã®æŠ½å‡ºã¨è§£æ
- `scraper.py`: ãƒ¡ã‚¤ãƒ³ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å‡¦ç†

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### å¿…è¦ç’°å¢ƒ

- Python 3.x
- MySQL 5.7ä»¥ä¸Š ã¾ãŸã¯ MariaDB 10.xä»¥ä¸Š

```bash
sudo apt install python3-pip
sudo apt install python3.12-venv
python3 -m venv venv
source venv/bin/activate  # Windowsãªã‚‰ venv\\Scripts\\activate
```

### ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

#### ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¿½åŠ ã—ãŸã¨ãã« `requirements.txt` ã‚’æ›´æ–°ã™ã‚‹

```bash
pip freeze > requirements.txt
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æº–å‚™

1. MySQLã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆï¼š
```bash
mysql -u root -h localhost -p
```
```sql
CREATE DATABASE scraping_db;
USE scraping_db;
GRANT all ON scraping_db.* TO 'your_user'@'localhost';
ALTER USER 'your_user'@'localhost' IDENTIFIED BY 'your_password';
```

2. å¿…è¦ãªãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼š
```bash
mysql -u your_user -p scraping_db < schema/scraped_pages.sql
mysql -u your_user -p scraping_db < schema/robots_rules.sql
```

## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š

`config.py`ã«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šæƒ…å ±ã‚’è¨­å®šã—ã¾ã™ï¼š

```python
DB_CONFIG = {
    'host': 'localhost',
    'user': 'your_user',
    'password': 'your_password',
    'database': 'scraping_db'
}
```

## ä½¿ç”¨æ–¹æ³•

### ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã®å®Ÿè¡Œ

åŸºæœ¬çš„ãªå®Ÿè¡Œï¼š
```bash
python scraper.py
```

ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®æŒ‡å®šï¼š
```bash
# ã‚«ã‚¹ã‚¿ãƒ User-agentã‚’æŒ‡å®šã—ã¦å®Ÿè¡Œ
python scraper.py --user-agent "CustomBot/1.0"
```

### ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®è¿½åŠ 

ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®URLã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¿½åŠ ã—ã¾ã™ï¼š

```sql
INSERT INTO scraped_pages (url, processed) VALUES ('https://example.com', FALSE);
```

### æ¨å¥¨é–‹ç™ºç’°å¢ƒ
- VisualStudioCode
  https://azure.microsoft.com/ja-jp/products/visual-studio-code
- A5:SQL Mk-2
  https://a5m2.mmatsubara.com/
  
## ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒ

### scraped_pages ãƒ†ãƒ¼ãƒ–ãƒ«

- `url`: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾è±¡ã®URLï¼ˆä¸»ã‚­ãƒ¼ï¼‰
- `referrer`: ãƒªãƒ³ã‚¯å…ƒã®URL
- `fetched_at`: å–å¾—æ—¥æ™‚
- `title`: ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«ã¾ãŸã¯ãƒªãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆ
- `content`: ãƒšãƒ¼ã‚¸ã®HTMLå†…å®¹
- `status_code`: HTTPã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰
- `hash`: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®ãƒãƒƒã‚·ãƒ¥å€¤
- `error_message`: ã‚¨ãƒ©ãƒ¼æƒ…å ±ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
- `processed`: å‡¦ç†æ¸ˆã¿ãƒ•ãƒ©ã‚°

### robots_rules ãƒ†ãƒ¼ãƒ–ãƒ«

- `domain`: ãƒ‰ãƒ¡ã‚¤ãƒ³åï¼ˆä¸»ã‚­ãƒ¼ï¼‰
- `user_agent`: User-agentæ–‡å­—åˆ—
- `disallow`: ç¦æ­¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰
- `allow`: è¨±å¯ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ”¹è¡ŒåŒºåˆ‡ã‚Šï¼‰
- `crawl_delay`: ã‚¯ãƒ­ãƒ¼ãƒ«é–“éš”ï¼ˆç§’ï¼‰
- `fetched_at`: å–å¾—æ—¥æ™‚
- `expires_at`: æœ‰åŠ¹æœŸé™ï¼ˆ24æ™‚é–“ï¼‰

## æ³¨æ„äº‹é …

- å¯¾è±¡ã‚µã‚¤ãƒˆã®robots.txtã‚’è‡ªå‹•çš„ã«ç¢ºèªãƒ»éµå®ˆã—ã¾ã™
- ã‚¯ãƒ­ãƒ¼ãƒ«é–“éš”ã¯robots.txtã®æŒ‡å®šã«å¾“ã„ã¾ã™
- ãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨ã¯å„ã‚µã‚¤ãƒˆã®åˆ©ç”¨è¦ç´„ã«å¾“ã£ã¦ãã ã•ã„
- ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã‚‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²ãŒæ®‹ã‚Šã¾ã™

## ã‚¨ãƒ©ãƒ¼å¯¾å‡¦

1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼
   - MySQLã‚µãƒ¼ãƒ“ã‚¹ã®èµ·å‹•ç¢ºèª
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨©é™ã®ç¢ºèª
   - æ¥ç¶šæƒ…å ±ã®ç¢ºèª

2. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼
   - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå€¤ã®èª¿æ•´ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 10ç§’ï¼‰
   - ãƒ—ãƒ­ã‚­ã‚·è¨­å®šã®ç¢ºèª
   - ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®šã®ç¢ºèª

---
## âœ… ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œæ–¹æ³•

### 1. å¿…è¦ãªç’°å¢ƒã®æº–å‚™
- Python 3.x
- `requests`, `beautifulsoup4`, `mysql-connector-python` ãªã©ã®ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼š
```bash
pip install -r requirements.txt
```

### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æº–å‚™ï¼ˆMySQLï¼‰
```bash
mysql -u root -h localhost -p
```
```sql
CREATE DATABASE scraping_db;
USE scraping_db;
GRANT all ON scraping_db.* TO 'your_user'@'localhost';
ALTER USER 'your_user'@'localhost' IDENTIFIED BY 'your_password';
```

- ã‚¹ã‚­ãƒ¼ãƒã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
```bash
mysql -u your_user -p scraping_db < schema/scraped_pages.sql
mysql -u your_user -p scraping_db < schema/robots_rules.sql
```

### 3. DBæ¥ç¶šè¨­å®šï¼ˆ`config.py`ï¼‰
```python
DB_CONFIG = {
    'host': 'localhost',
    'user': 'your_user',
    'password': 'your_password',
    'database': 'scraping_db'
}
```

### 4. ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ `tests/` ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚Šã€`pytest` ã§å®Ÿè¡Œå¯èƒ½ã§ã™ï¼š

```bash
PYTHONPATH=. pytest
```

ç‰¹å®šã®ãƒ†ã‚¹ãƒˆã ã‘ã‚’å®Ÿè¡Œã—ãŸã„å ´åˆï¼š
```bash
pytest tests/test_scrape.py
```

### 5. ãƒ¢ãƒƒã‚¯ã‚’ä½¿ã£ãŸãƒ†ã‚¹ãƒˆä¾‹
`test_scrape_failure(mock_get)` ã¨ã„ã†é–¢æ•°ãŒç¢ºèªã•ã‚Œã¦ãŠã‚Šã€`requests.get` ã‚’ãƒ¢ãƒƒã‚¯ã—ã¦å¤±æ•—ã‚±ãƒ¼ã‚¹ã‚’æ¤œè¨¼ã—ã¦ã„ã¾ã™ã€‚`pytest-mock` ãŒå¿…è¦ãªå ´åˆã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼š

```bash
pip install pytest-mock
```

---

## å‚è€ƒè³‡æ–™

- [Requests ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://requests.readthedocs.io/ja/latest/)
- [BeautifulSoup ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [MySQLã‚³ãƒã‚¯ã‚¿/Python](https://dev.mysql.com/doc/connector-python/en/)
- [MariaDBã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰](https://qiita.com/nanbuwks/items/c98c51744bd0f72a7087) https://qiita.com/nanbuwks/items/c98c51744bd0f72a7087

